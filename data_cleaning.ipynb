{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this cell was only ran once, doesn't need to be run each time\n",
    "# pollutants = ['CO/', 'NO2/', 'Ozone/', 'PM2.5/', 'PM10/', 'SO2/']\n",
    "\n",
    "# # read in files and create dataframe of all data for each pollutant\n",
    "# for pollutant in pollutants:\n",
    "#     # empty list to store dfs\n",
    "#     dfs = []\n",
    "#     # iterate through files in the directory\n",
    "#     for filename in os.listdir('data/' + pollutant):\n",
    "#         df = pd.read_csv('data/' + pollutant + filename)\n",
    "\n",
    "#         if pollutant == 'PM2.5/':\n",
    "#             # only keep local conditions of pm2.5\n",
    "#             df = df[df[\"AQS Parameter Description\"] == \"PM2.5 - Local Conditions\"]\n",
    "#         dfs.append(df)\n",
    "\n",
    "#     # concatenate all dfs in the list\n",
    "#     merged_df = pd.concat(dfs, ignore_index=True)\n",
    "#     df = merged_df.drop(columns=[\"POC\", \"Source\", \"Local Site Name\", \"Percent Complete\", \"AQS Parameter Code\", \"AQS Parameter Description\", \"Method Code\", \"CBSA Code\", \"CBSA Name\", \"State FIPS Code\", \"State\", \"Units\"])\n",
    "\n",
    "#     # save the merged DataFrame to a new CSV file\n",
    "#     df.to_csv('data/All/all_' + pollutant[:-1] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: feel free to edit this cell to make the data cleaner, but otherwise it doesn't need to be run\n",
    "# read in dataframes for each pollutant and merge into 1\n",
    "# df_CO = pd.read_csv('data/All/all_CO.csv')\n",
    "# df_NO2 = pd.read_csv('data/All/all_NO2.csv')\n",
    "# df_Ozone = pd.read_csv('data/All/all_Ozone.csv')\n",
    "# df_PM2_5 = pd.read_csv('data/All/all_PM2.5.csv')\n",
    "# df_PM10 = pd.read_csv('data/All/all_PM10.csv')\n",
    "# df_SO2 = pd.read_csv('data/All/all_SO2.csv')\n",
    "\n",
    "# cols = ['Date', 'Site ID', 'County FIPS Code', 'County', 'Site Latitude', 'Site Longitude']\n",
    "\n",
    "# mergedCO_NO2 = df_CO.merge(df_NO2, on=cols, how=\"outer\", suffixes=(' CO', ' NO2'))\n",
    "# mergedOzone_PM2 = df_Ozone.merge(df_PM2_5, on=cols, how=\"outer\", suffixes=(' Ozone', ' PM2.5'))\n",
    "# mergedPM10_SO2 = df_PM10.merge(df_SO2, on=cols, how=\"outer\", suffixes=(' PM10', ' SO2'))\n",
    "# mergedCO_NO2_Ozone_PM2 = mergedCO_NO2.merge(mergedOzone_PM2, on=cols, how=\"outer\")\n",
    "# all_merged = mergedCO_NO2_Ozone_PM2.merge(df_PM10, on=cols, how='outer').drop(columns=[\"Method Description\"])\n",
    "\n",
    "# # reorder cols\n",
    "# col_order = [\"Date\", \"Site ID\", \"County\", \"County FIPS Code\", \"Site Latitude\", \"Site Longitude\", \n",
    "#              \"Daily Max 8-hour CO Concentration\", \"Daily AQI Value CO\", \"Daily Obs Count CO\", \n",
    "#              \"Daily Max 1-hour NO2 Concentration\", \"Daily AQI Value NO2\", \"Daily Obs Count NO2\", \n",
    "#              \"Daily Max 8-hour Ozone Concentration\", \"Daily AQI Value Ozone\", \"Daily Obs Count Ozone\", \n",
    "#              \"Daily Mean PM2.5 Concentration\", \"Daily AQI Value PM2.5\", \"Daily Obs Count PM2.5\",\n",
    "#              \"Daily Mean PM10 Concentration\", \"Daily AQI Value\", \"Daily Obs Count\"]\n",
    "# all_merged = all_merged[col_order]\n",
    "# all_merged.to_csv('data/All/all_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: columns are measured in different units. CO: ppm, NO2: ppb, Ozone: ppm, PM2.5: ug/m3 LC, PM10: ug/m3 SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataframe\n",
    "df = pd.read_csv('data/All/all_merged.csv', usecols=lambda column: \"Unnamed\" not in column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site ID</th>\n",
       "      <th>County</th>\n",
       "      <th>County FIPS Code</th>\n",
       "      <th>Site Latitude</th>\n",
       "      <th>Site Longitude</th>\n",
       "      <th>Daily Max 8-hour CO Concentration</th>\n",
       "      <th>Daily AQI Value CO</th>\n",
       "      <th>Daily Obs Count CO</th>\n",
       "      <th>Daily Max 1-hour NO2 Concentration</th>\n",
       "      <th>Daily AQI Value NO2</th>\n",
       "      <th>Daily Obs Count NO2</th>\n",
       "      <th>Daily Max 8-hour Ozone Concentration</th>\n",
       "      <th>Daily AQI Value Ozone</th>\n",
       "      <th>Daily Obs Count Ozone</th>\n",
       "      <th>Daily Mean PM2.5 Concentration</th>\n",
       "      <th>Daily AQI Value PM2.5</th>\n",
       "      <th>Daily Obs Count PM2.5</th>\n",
       "      <th>Daily Mean PM10 Concentration</th>\n",
       "      <th>Daily AQI Value</th>\n",
       "      <th>Daily Obs Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2015</td>\n",
       "      <td>490030003</td>\n",
       "      <td>Box Elder</td>\n",
       "      <td>3</td>\n",
       "      <td>41.492707</td>\n",
       "      <td>-112.018863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2015</td>\n",
       "      <td>490037001</td>\n",
       "      <td>Box Elder</td>\n",
       "      <td>3</td>\n",
       "      <td>41.945874</td>\n",
       "      <td>-112.233973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2015</td>\n",
       "      <td>490050004</td>\n",
       "      <td>Cache</td>\n",
       "      <td>5</td>\n",
       "      <td>41.731111</td>\n",
       "      <td>-111.837500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2015</td>\n",
       "      <td>490050004</td>\n",
       "      <td>Cache</td>\n",
       "      <td>5</td>\n",
       "      <td>41.731111</td>\n",
       "      <td>-111.837500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2015</td>\n",
       "      <td>490071003</td>\n",
       "      <td>Carbon</td>\n",
       "      <td>7</td>\n",
       "      <td>39.595750</td>\n",
       "      <td>-110.770111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045</td>\n",
       "      <td>42.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Site ID     County  County FIPS Code  Site Latitude  \\\n",
       "0  01/01/2015  490030003  Box Elder                 3      41.492707   \n",
       "1  01/01/2015  490037001  Box Elder                 3      41.945874   \n",
       "2  01/01/2015  490050004      Cache                 5      41.731111   \n",
       "3  01/01/2015  490050004      Cache                 5      41.731111   \n",
       "4  01/01/2015  490071003     Carbon                 7      39.595750   \n",
       "\n",
       "   Site Longitude  Daily Max 8-hour CO Concentration  Daily AQI Value CO  \\\n",
       "0     -112.018863                                NaN                 NaN   \n",
       "1     -112.233973                                NaN                 NaN   \n",
       "2     -111.837500                                NaN                 NaN   \n",
       "3     -111.837500                                NaN                 NaN   \n",
       "4     -110.770111                                NaN                 NaN   \n",
       "\n",
       "   Daily Obs Count CO  Daily Max 1-hour NO2 Concentration  \\\n",
       "0                 NaN                                 NaN   \n",
       "1                 NaN                                 NaN   \n",
       "2                 NaN                                35.0   \n",
       "3                 NaN                                35.0   \n",
       "4                 NaN                                 NaN   \n",
       "\n",
       "   Daily AQI Value NO2  Daily Obs Count NO2  \\\n",
       "0                  NaN                  NaN   \n",
       "1                  NaN                  NaN   \n",
       "2                 33.0                 24.0   \n",
       "3                 33.0                 24.0   \n",
       "4                  NaN                  NaN   \n",
       "\n",
       "   Daily Max 8-hour Ozone Concentration  Daily AQI Value Ozone  \\\n",
       "0                                   NaN                    NaN   \n",
       "1                                 0.036                   33.0   \n",
       "2                                 0.027                   25.0   \n",
       "3                                 0.027                   25.0   \n",
       "4                                 0.045                   42.0   \n",
       "\n",
       "   Daily Obs Count Ozone  Daily Mean PM2.5 Concentration  \\\n",
       "0                    NaN                             5.0   \n",
       "1                   17.0                             NaN   \n",
       "2                   17.0                            16.2   \n",
       "3                   17.0                            15.3   \n",
       "4                   17.0                             NaN   \n",
       "\n",
       "   Daily AQI Value PM2.5  Daily Obs Count PM2.5  \\\n",
       "0                   28.0                    1.0   \n",
       "1                    NaN                    NaN   \n",
       "2                   64.0                    1.0   \n",
       "3                   63.0                    1.0   \n",
       "4                    NaN                    NaN   \n",
       "\n",
       "   Daily Mean PM10 Concentration  Daily AQI Value  Daily Obs Count  \n",
       "0                            NaN              NaN              NaN  \n",
       "1                            NaN              NaN              NaN  \n",
       "2                            NaN              NaN              NaN  \n",
       "3                            NaN              NaN              NaN  \n",
       "4                            NaN              NaN              NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 5 rows of data\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Type Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object columns to string\n",
    "df[df.select_dtypes(include=['object']).columns] = df.select_dtypes(include=['object']).astype('string')\n",
    "\n",
    "# Convert date column to datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 9812 duplicated data points\n"
     ]
    }
   ],
   "source": [
    "# Find and remove duplicated data\n",
    "duplicates = df.duplicated()\n",
    "print(\"Removing\",df[duplicates].shape[0], \"duplicated data points\")\n",
    "df = df[-df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling (we may not want to do this?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only float columns\n",
    "df_floats = df.select_dtypes(include=['float']).copy()\n",
    "\n",
    "# Apply MinMaxScaler, allowing NaN values to persist\n",
    "scaler = MinMaxScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df_floats), columns=df_floats.columns, index=df.index)\n",
    "df = df.replace({pd.NA: np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute Missing Values (Warning: this cell takes roughly 20 minutes to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with at least 10 missing values\n",
    "df = df.dropna(thresh=df.shape[1] - 10 + 1)  # Keep rows with at least (total columns - 15 + 1) non-NaN value\n",
    "\n",
    "# Using KNN to impute the remaining missing values in the DataFrame. \n",
    "# The highest percentage of missing values in any single column is approximately 10%, \n",
    "# making KNN a suitable imputation method.\n",
    "\n",
    "# Initialize KNN imputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Apply KNN imputation\n",
    "df[df.columns] = df[df.columns].apply(pd.to_numeric, errors='coerce')\n",
    "df = df.copy()  # Preserve original DataFrame\n",
    "df[df.columns] = imputer.fit_transform(df[df.columns])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
